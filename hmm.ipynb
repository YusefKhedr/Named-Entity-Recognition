{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Hidden Markov Model\n",
    "\n",
    "### Author: Omer Waseem\n",
    "#### Description: This Python notebook trains and evaluates a HMM using the CoNLL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataprep import conll_words\n",
    "from helper import accuracy, entity_count\n",
    "import nltk\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CoNLL data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = './datasets/CoNLL2003/eng.train'\n",
    "testa_file = './datasets/CoNLL2003/eng.testa'\n",
    "testb_file = './datasets/CoNLL2003/eng.testb'\n",
    "testc_file = './datasets/CoNLL2003/eng.testc'\n",
    "\n",
    "train_words, _, _, train_entities = conll_words(train_file)\n",
    "testa_words, _, _, testa_entities = conll_words(testa_file)\n",
    "testb_words, _, _, testb_entities = conll_words(testb_file)\n",
    "testc_words, _, _, testc_entities = conll_words(testc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine training and testing datasets to form vocabulary and entitiy sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_words = train_words + testa_words + testb_words + testc_words\n",
    "combined_entities = train_entities + testa_entities + testb_entities + testc_entities\n",
    "\n",
    "char_set = set()\n",
    "for word in combined_words:\n",
    "    for char in word:\n",
    "        char_set.add(char)\n",
    "entity_set = set(combined_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Unsupervised HMM\n",
    "#### Note: testa is used for training since it is smaller in size, and unsupervised learning is used. This is to allow for more training interations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 logprob -1426557.50223\n",
      "iteration 1 logprob -1117558.59144\n",
      "iteration 2 logprob -1110369.70708\n",
      "iteration 3 logprob -1102886.49849\n",
      "iteration 4 logprob -1094904.86769\n",
      "iteration 5 logprob -1085588.68258\n",
      "iteration 6 logprob -1073468.57339\n",
      "iteration 7 logprob -1059869.72322\n",
      "iteration 8 logprob -1048842.1155\n",
      "iteration 9 logprob -1041855.9449\n",
      "iteration 10 logprob -1036274.63472\n",
      "iteration 11 logprob -1030640.56712\n",
      "iteration 12 logprob -1024878.88372\n",
      "iteration 13 logprob -1019548.33273\n",
      "iteration 14 logprob -1015174.90795\n",
      "iteration 15 logprob -1011786.20334\n",
      "iteration 16 logprob -1009071.15325\n",
      "iteration 17 logprob -1006673.13257\n",
      "iteration 18 logprob -1004356.02605\n",
      "iteration 19 logprob -1002096.77448\n",
      "iteration 20 logprob -999971.392286\n",
      "iteration 21 logprob -997999.821362\n",
      "iteration 22 logprob -996151.791588\n",
      "iteration 23 logprob -994426.07502\n",
      "iteration 24 logprob -992869.202776\n",
      "iteration 25 logprob -991524.965157\n",
      "iteration 26 logprob -990393.249284\n",
      "iteration 27 logprob -989438.716187\n",
      "iteration 28 logprob -988613.487968\n",
      "iteration 29 logprob -987876.138526\n",
      "iteration 30 logprob -987210.32303\n",
      "iteration 31 logprob -986617.606678\n",
      "iteration 32 logprob -986093.114049\n",
      "iteration 33 logprob -985622.145005\n",
      "iteration 34 logprob -985189.278604\n",
      "iteration 35 logprob -984787.90788\n",
      "iteration 36 logprob -984423.163231\n",
      "iteration 37 logprob -984104.410026\n",
      "iteration 38 logprob -983834.137683\n",
      "iteration 39 logprob -983605.365538\n",
      "iteration 40 logprob -983407.189985\n",
      "iteration 41 logprob -983228.381485\n",
      "iteration 42 logprob -983055.981669\n",
      "iteration 43 logprob -982872.577896\n",
      "iteration 44 logprob -982672.527676\n",
      "iteration 45 logprob -982475.218766\n",
      "iteration 46 logprob -982287.438036\n",
      "iteration 47 logprob -982101.017416\n",
      "iteration 48 logprob -981908.41096\n",
      "iteration 49 logprob -981707.892985\n",
      "iteration 50 logprob -981502.790355\n",
      "iteration 51 logprob -981296.783435\n",
      "iteration 52 logprob -981091.055802\n",
      "iteration 53 logprob -980886.14459\n",
      "iteration 54 logprob -980684.366486\n",
      "iteration 55 logprob -980489.612392\n",
      "iteration 56 logprob -980305.603383\n",
      "iteration 57 logprob -980132.675783\n",
      "iteration 58 logprob -979959.901851\n",
      "iteration 59 logprob -979754.330549\n",
      "iteration 60 logprob -979493.119143\n",
      "iteration 61 logprob -979261.589784\n",
      "iteration 62 logprob -979118.399671\n",
      "iteration 63 logprob -979024.551825\n",
      "iteration 64 logprob -978957.014475\n",
      "iteration 65 logprob -978907.069119\n",
      "iteration 66 logprob -978869.234134\n",
      "iteration 67 logprob -978839.418749\n",
      "iteration 68 logprob -978814.550245\n",
      "iteration 69 logprob -978792.355211\n",
      "iteration 70 logprob -978771.130376\n",
      "iteration 71 logprob -978749.588448\n",
      "iteration 72 logprob -978727.120387\n",
      "iteration 73 logprob -978704.576353\n",
      "iteration 74 logprob -978683.923216\n",
      "iteration 75 logprob -978665.206145\n",
      "iteration 76 logprob -978643.413633\n",
      "iteration 77 logprob -978610.689262\n",
      "iteration 78 logprob -978572.366675\n",
      "iteration 79 logprob -978545.110783\n",
      "iteration 80 logprob -978528.442653\n",
      "iteration 81 logprob -978516.935649\n",
      "iteration 82 logprob -978508.478522\n",
      "iteration 83 logprob -978502.071637\n",
      "iteration 84 logprob -978497.069645\n",
      "iteration 85 logprob -978493.041454\n",
      "iteration 86 logprob -978489.701536\n",
      "iteration 87 logprob -978486.86114\n",
      "iteration 88 logprob -978484.394231\n",
      "iteration 89 logprob -978482.214439\n",
      "iteration 90 logprob -978480.25968\n",
      "iteration 91 logprob -978478.481855\n",
      "iteration 92 logprob -978476.839882\n",
      "iteration 93 logprob -978475.295144\n",
      "iteration 94 logprob -978473.809322\n",
      "iteration 95 logprob -978472.34482\n",
      "iteration 96 logprob -978470.866794\n",
      "iteration 97 logprob -978469.343678\n",
      "iteration 98 logprob -978467.743465\n",
      "iteration 99 logprob -978466.027621\n"
     ]
    }
   ],
   "source": [
    "trainer = nltk.tag.hmm.HiddenMarkovModelTrainer(states=entity_set, symbols=char_set)\n",
    "model = trainer.train_unsupervised(testa_words, max_iterations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on testb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testb_result = model.tag(testb_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SOCCER', 'LOC'),\n",
       " ('-', 'LOC'),\n",
       " ('JAPAN', 'LOC'),\n",
       " ('GET', 'LOC'),\n",
       " ('LUCKY', 'LOC')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testb_result[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testb_predicted = []\n",
    "for word, entity in testb_result:\n",
    "    testb_predicted.append(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 1925 / 46435 = 0.041456\n"
     ]
    }
   ],
   "source": [
    "accuracy(testb_entities, testb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ow/anaconda/envs/datamgt/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.0414558,  0.       ,  0.       ,  0.       ,  0.       ]),\n",
       " array([ 1.,  0.,  0.,  0.,  0.]),\n",
       " array([ 0.07961125,  0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " array([ 1925,   918, 38323,  2496,  2773]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(testb_entities, testb_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORG: 2496\n",
      "PER: 2773\n",
      "LOC: 1925\n",
      "MISC: 918\n",
      "O: 38323\n"
     ]
    }
   ],
   "source": [
    "entity_count(testb_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
